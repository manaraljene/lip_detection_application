import streamlit as st
import os
import cv2
import tensorflow as tf
from lip_extractor import process_video
from tensorflow.keras.models import load_model
import numpy as np

# Charger la liste des mots cibles
WORDS_LIST = [
    "Stop navigation .", "Excuse me .", "I am sorry .", "Thank you .", "Good bye .", "I love this game .",
    "Nice to meet you .", "You are welcome", "How are you ?", "Have a good time .",
    "Begin", "Choose", "Connection", "Navigation", "Next", "Previous", "Start", "Stop", "Hello", "Web"
]

# Charger le mod√®le sauvegard√©
model_path = "C:/Users/manar/Documents/pfa_app/app1/lip_reading_model.h5"
model = load_model(model_path)

# Titre de l'application
st.title("Lip Reading App üé•üëÑ")

# Diviser l'interface en deux colonnes
col1, col2 = st.columns([1, 3])  # La colonne gauche est plus √©troite que la droite

# Ajouter une image dans la colonne de gauche
with col1:
    st.image("C:/Users/manar/Pictures/Screenshots/mots.png", caption="Les mots possibles", use_container_width=True)

# Contenu principal dans la colonne de droite
with col2:
    # Options pour l'utilisateur : charger une vid√©o ou capturer en temps r√©el
    option = st.radio(
        "Choisissez une option‚ÄØ:",
        ("Charger une vid√©o existante", "Capturer une vid√©o avec la cam√©ra (2 secondes)")
    )

    # Charger une vid√©o existante
    if option == "Charger une vid√©o existante":
        # T√©l√©chargement de la vid√©o
        uploaded_video = st.file_uploader("T√©l√©chargez une vid√©o", type=["mp4", "avi", "mov"])
        os.makedirs("uploads", exist_ok=True)
        os.makedirs("extracted", exist_ok=True)

        if uploaded_video is not None:
            video_path = os.path.join("uploads", uploaded_video.name)
            with open(video_path, "wb") as f:
                f.write(uploaded_video.read())
            st.success("‚úÖ Vid√©o t√©l√©charg√©e!")

            if st.button("Extraire les l√®vres et pr√©dire"):
                output_path = process_video(video_path, "extracted", grid_size=(7, 7))

                if output_path:
                    st.image(output_path, caption="Grille des l√®vres extraites")
                    st.success("‚úÖ R√©gion des l√®vres extraite!")

                    # Charger et pr√©traiter l'image de grille pour la pr√©diction
                    lip_grid = tf.keras.preprocessing.image.load_img(output_path, target_size=(224, 224))
                    lip_grid = tf.keras.preprocessing.image.img_to_array(lip_grid)
                    lip_grid = np.expand_dims(lip_grid, axis=0)
                    lip_grid = lip_grid / 255.0

                    # Effectuer une pr√©diction
                    predictions = model.predict(lip_grid)
                    predicted_word_index = np.argmax(predictions)
                    predicted_word = WORDS_LIST[predicted_word_index]

                    st.success(f"Le mot pr√©dit est : **{predicted_word}** üëÑ")
                else:
                    st.error("‚ùå Aucune l√®vre d√©tect√©e.")

    # Capturer une vid√©o de 2 secondes avec la webcam
    elif option == "Capturer une vid√©o avec la cam√©ra (2 secondes)":
        if st.button("D√©marrer la capture vid√©o"):
            # D√©marrer la capture vid√©o
            cap = cv2.VideoCapture(0)  # Webcam par d√©faut
            os.makedirs("real_time_videos", exist_ok=True)
            video_path = "real_time_videos/real_time_video.mp4"

            # D√©finir le codec et le format vid√©o
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(video_path, fourcc, 20.0, (640, 480))  # FPS = 20, r√©solution = 640x480

            st.write("‚è≥ Enregistrement pendant 2 secondes...")
            start_time = cv2.getTickCount()
            duration_seconds = 2  # 2 secondes

            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break

                out.write(frame)  # √âcriture des frames dans la vid√©o

                # Calcul du temps √©coul√©
                elapsed_time = (cv2.getTickCount() - start_time) / cv2.getTickFrequency()
                if elapsed_time >= duration_seconds:
                    break

            # Lib√©rer les ressources
            cap.release()
            out.release()
            cv2.destroyAllWindows()
            st.success("‚úÖ Vid√©o captur√©e!")

            # Traiter la vid√©o captur√©e
            st.write("üîÑ Transformation en matrice et pr√©diction...")
            output_path = process_video(video_path, "extracted", grid_size=(7, 7))

            if output_path:
                st.image(output_path, caption="Grille des l√®vres extraites")
                st.success("‚úÖ R√©gion des l√®vres extraite!")

                # Pr√©traiter l'image de la grille
                lip_grid = tf.keras.preprocessing.image.load_img(output_path, target_size=(224, 224))
                lip_grid = tf.keras.preprocessing.image.img_to_array(lip_grid)
                lip_grid = np.expand_dims(lip_grid, axis=0)
                lip_grid = lip_grid / 255.0

                # Effectuer une pr√©diction
                predictions = model.predict(lip_grid)
                predicted_word_index = np.argmax(predictions)
                predicted_word = WORDS_LIST[predicted_word_index]

                st.success(f"Le mot pr√©dit est : **{predicted_word}** üëÑ")
            else:
                st.error("‚ùå Aucune l√®vre d√©tect√©e.")